# -*- coding: utf-8 -*-
"""Copy of MY SNGAN w/ horses birds and airplanes

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18JHFVFftN2uQ72_RZI_vhpKZ1XYya7GK
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# from os.path import exists
# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag
# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())
# cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\.\([0-9]*\)\.\([0-9]*\)$/cu\1\2/'
# accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'
# !pip install -q torch torchvision livelossplot

"""**Main imports**"""

import math
import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import matplotlib.pyplot as plt
from time import sleep
from livelossplot import PlotLosses
import os
from google.colab import drive
drive.mount('/content/drive')

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

"""**Import dataset**"""

# helper function to make getting another batch of data easier
def cycle(iterable):
    while True:
        for x in iterable:
            yield x

class_names = ['airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

train_loader = torch.utils.data.DataLoader(
    torchvision.datasets.CIFAR10('data', train=True, download=True, transform=torchvision.transforms.Compose([
        torchvision.transforms.ToTensor()
    ])),
shuffle=True, batch_size=64, drop_last=True)

"""**Separate horses and planes into their own dataset**"""

horse_plane_images = []
horse_plane_labels = []

# seperating out horses into a new dataset and dataloader
for i in range(0, len(train_loader.dataset)):

  class_label = train_loader.dataset[i][1]
  if class_label == 0 or class_label == 2 or class_label == 7:  # plane or horse
    image, label = train_loader.dataset[i]
    horse_plane_images.append(image)
    horse_plane_labels.append(label)

horse_plane_images = torch.stack(horse_plane_images)
horse_plane_labels = torch.LongTensor(horse_plane_labels)

horse_plane_dataset = torch.utils.data.TensorDataset(horse_plane_images, horse_plane_labels)
horse_plane_train_loader = torch.utils.data.DataLoader(horse_plane_dataset, shuffle=True, batch_size=64, drop_last=True)

horse_plane_train_iterator = iter(cycle(horse_plane_train_loader))
print(f'> Size of training dataset {len(horse_plane_train_loader.dataset)}')

"""**Define two models: (1) Generator, and (2) Discriminator**"""

# define the model
class Generator(nn.Module):
    def __init__(self, f=64):
        super(Generator, self).__init__()
        self.generate = nn.Sequential(
            nn.ConvTranspose2d(100, f*8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64*8),
            nn.ReLU(True),
            nn.ConvTranspose2d(f*8, f*4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(f*4),
            nn.ReLU(True),
            nn.ConvTranspose2d(f*4, f*2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(f*2),
            nn.ReLU(True),
            nn.ConvTranspose2d(f*2, f, 4, 2, 1, bias=False),
            nn.BatchNorm2d(f),
            nn.ReLU(True),
            nn.ConvTranspose2d(f, 3, 4, 2, 1, bias=False),
            nn.Sigmoid()
        )

# try mean pooling
class Discriminator(nn.Module):
    def __init__(self, f=64):
        super(Discriminator, self).__init__()
        self.discriminate = nn.Sequential(
            torch.nn.utils.spectral_norm(nn.Conv2d(3, f, 3, 1, 1)),
            nn.LeakyReLU(0.1, inplace=True),
            nn.MaxPool2d(kernel_size=(2,2)),
            torch.nn.utils.spectral_norm(nn.Conv2d(f, f*2, 3, 1, 1)),
            nn.LeakyReLU(0.1, inplace=True),
            nn.MaxPool2d(kernel_size=(2,2)),
            torch.nn.utils.spectral_norm(nn.Conv2d(f*2, f*4, 3, 1, 1)),
            nn.LeakyReLU(0.1, inplace=True),
            nn.MaxPool2d(kernel_size=(2,2)),
            torch.nn.utils.spectral_norm(nn.Conv2d(f*4, f*8, 3, 1, 1)),
            nn.LeakyReLU(0.1, inplace=True),
            nn.MaxPool2d(kernel_size=(2,2)),
            torch.nn.utils.spectral_norm(nn.Conv2d(f*8, 1, 3, 1, 1)),
            nn.MaxPool2d(kernel_size=(2,2)),
            nn.Sigmoid()
        )

# create separate G and Ds for horses and birds, and two for the pegasus generator
horse_plane_G = Generator().to(device)
horse_plane_D = Discriminator().to(device)

# load previously trained generator and discriminator each for horse and plane
epoch_number = 200

horse_plane_g_path = F"/content/drive/My Drive/University Work/Year 3/Software, Systems, & Applications III/Deep Learning/horse_plane_generator_{epoch_number}.pth"
horse_plane_d_path = F"/content/drive/My Drive/University Work/Year 3/Software, Systems, & Applications III/Deep Learning/horse_plane_discriminator_{epoch_number}.pth"
horse_plane_G.load_state_dict(torch.load(horse_plane_g_path))
horse_plane_D.load_state_dict(torch.load(horse_plane_d_path))

# initialise the optimiser
horse_plane_optimiser_G = torch.optim.Adam(horse_plane_G.parameters(), lr=0.001)
horse_plane_optimiser_D = torch.optim.Adam(horse_plane_D.parameters(), lr=0.001)

bce_loss = nn.BCELoss()
epoch = 0
liveplot = PlotLosses()

"""**Main training loop for both horses and planes**"""

epoch = 0
liveplot = PlotLosses()

# training loop
while (epoch<201):
    
    # arrays for metrics
    logs = {}
    gen_loss_arr = np.zeros(0)
    dis_loss_arr = np.zeros(0)

    # iterate over some of the train dateset
    for i in range(100):

        # train discriminator 
        for j in range(5):
            x,t = next(horse_plane_train_iterator)
            x,t = x.to(device), t.to(device)
            horse_plane_optimiser_D.zero_grad()
            g = horse_plane_G.generate(torch.randn(x.size(0), 100, 1, 1).to(device))
            l_r = bce_loss(horse_plane_D.discriminate(x).mean(), torch.ones(1)[0].to(device)) # real -> 1
            l_f = bce_loss(horse_plane_D.discriminate(g.detach()).mean(), torch.zeros(1)[0].to(device)) #  fake -> 0
            loss_d = (l_r + l_f)/2.0
            loss_d.backward()
            horse_plane_optimiser_D.step()
          
        # train generator
        x,t = next(horse_plane_train_iterator)
        x,t = x.to(device), t.to(device)
        horse_plane_optimiser_G.zero_grad()
        g = horse_plane_G.generate(torch.randn(x.size(0), 100, 1, 1).to(device))
        loss_g = bce_loss(horse_plane_D.discriminate(g).mean(), torch.ones(1)[0].to(device)) # fake -> 1
        loss_g.backward()
        horse_plane_optimiser_G.step()

        gen_loss_arr = np.append(gen_loss_arr, loss_g.item())
        dis_loss_arr = np.append(dis_loss_arr, loss_d.item())

    # saving the model once it finishes running
    if epoch == 200:
      torch.save(horse_plane_G.state_dict(), os.path.join('/', 'content', 'drive', 'My Drive', 'University Work', 'Year 3', 'Software, Systems, & Applications III', 'Deep Learning', f'horse_plane_generator_{epoch}.pth'))
      torch.save(horse_plane_D.state_dict(), os.path.join('/', 'content', 'drive', 'My Drive', 'University Work', 'Year 3', 'Software, Systems, & Applications III', 'Deep Learning', f'horse_plane_discriminator_{epoch}.pth'))
    
    # plot some examples
    plt.grid(False)
    plt.imshow(torchvision.utils.make_grid(g).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)

    liveplot.update({
        'generator loss': gen_loss_arr.mean(),
        'discriminator loss': dis_loss_arr.mean()
    })
    liveplot.draw()
    sleep(1.)

    epoch = epoch + 1

"""**Generate a seed for choosing horses for interpolation**"""

horse_plane_G.eval()

horse_seed = random.randint(0, 1000000000)
print(horse_seed)

torch.manual_seed(horse_seed)
horses = horse_plane_G.generate(torch.randn(100, 100, 1, 1).to(device))

plt.figure(figsize=(25, 10))
for i in range(50):
    plt.subplot(5,10,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(horses[i].permute(0,2,1).cpu().detach().contiguous().permute(2,1,0), cmap=plt.cm.binary)

"""**Select an appropriate horse for interpolation**"""

torch.manual_seed(horse_seed)

z_horse = torch.randn(100, 100, 1, 1).to(device)[24]
z_horse = z_horse.unsqueeze(0)
horse = horse_plane_G.generate(z_horse)
plt.imshow(horse[0].cpu().data.permute(0, 2, 1).contiguous().permute(2, 1, 0), cmap=plt.cm.binary)

"""**Generate a seed for choosing birds for interpolation**"""

plane_seed = random.randint(0, 1000000000)
print(plane_seed)
torch.manual_seed(plane_seed)
planes = horse_plane_G.generate(torch.randn(100, 100, 1, 1).to(device))

plt.figure(figsize=(25,20))
for i in range(100):
    plt.subplot(10,10,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(planes[i].permute(0,2,1).cpu().detach().contiguous().permute(2,1,0), cmap=plt.cm.binary)

"""**Select an appropriate bird for interpolation**"""

torch.manual_seed(plane_seed)

z_plane = torch.randn(100, 100, 1, 1).to(device)[37]
z_plane = z_plane.unsqueeze(0)

plane = horse_plane_G.generate(z_plane)

plt.imshow(plane[0].permute(0,2,1).cpu().detach().contiguous().permute(2,1,0), cmap=plt.cm.binary)

"""**Generate a Pegasus via interpolation by displaying 100 combinations of the horse and bird**"""

horse_plane_G.eval()

for horse_proportion in np.arange(0, 1, 0.01):

  z_pegasus = (horse_proportion * z_horse) + ((1 - horse_proportion) * z_plane)
  z_pegasus = horse_plane_G.generate(z_pegasus)

  plt.figure()
  plt.imshow(z_pegasus[0].permute(0,2,1).cpu().detach().contiguous().permute(2,1,0), cmap=plt.cm.binary)

horse_plane_G.eval()

z_pegasus = (0.95 * z_horse) + (0.75 * z_plane)
z_pegasus = horse_plane_G.generate(z_pegasus)

plt.figure()
plt.imshow(z_pegasus[0].permute(0,2,1).cpu().detach().contiguous().permute(2,1,0), cmap=plt.cm.binary)

"""Sample a batch from the generative model to show the output diversity"""

batch = G.generate(torch.randn(x.size(0), 100, 1, 1).to(device))

plt.figure(figsize=(10,10))
for i in range(64):
    plt.subplot(8,8,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(batch[i].cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)